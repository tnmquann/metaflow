params {
    // Input options
    input = null               // Path to input CSV file e.g. 'samples.csv'
    trimmed_fastq = null      // Path to directory of trimmed FASTQ files (for input_format = 'directory')
    input_format = 'csv'      // Format of input: 'csv' or 'directory'

    // Output options
    outdir = "./results"       // Default output directory

    // Directory structure (relative to params.outdir)
    merged_seq_dir = "${params.outdir}/Merged sequences"
    sketches_dir = "${params.outdir}/Sourmash - YACHT/sketches"
    yacht_results_dir = "${params.outdir}/Sourmash - YACHT"
    fastmultigather_dir = "${params.outdir}/Sourmash - YACHT"
    processed_results_dir = "${params.outdir}/Sourmash - YACHT"

    // QC and Preprocessing output directories
    qc_raw_dir = "${params.outdir}/QC/Raw_reads"
    qc_trim_dir = "${params.outdir}/QC/Trimming"
    qc_rmhost_dir = "${params.outdir}/QC/Remove host genome"
    trim_dir = "${params.outdir}/Trimming"
    rmhost_dir = "${params.outdir}/Remove host genome"

    // Tool parameters
    ksize = 31
    sourmash_database = null
    yacht_database = null

    // Resource parameters - Add these
    max_cpus = 20
    max_memory = '60.GB'
    max_time = '24.h'

    // Hostile reference parameters
    hostile_reference = null
    hostile_index = "human-t2t-hla"  // Set default reference name
    hostile_ref_name = "human-t2t-hla"  // Add this new parameter for explicit reference name

    // Optional parameters for nf-core modules
    multiqc_config = null
    multiqc_extra_config = null
    multiqc_logo = null
    multiqc_replace_names = null
    multiqc_sample_names = null
    fastp_adapter_fasta = null
    fastp_save_trimmed_fail = false
    fastp_save_merged = false

    // Publishing mode
    publish_dir_mode = 'copy'
}

// Process resource configuration
process {
    // Variables for computing resource allocation
    // Users are recommended to adjust accordingly to their machines
    DEFAULT_MAX_CPU = 1
    DEFAULT_MAX_MEM = 7.GB
    DEFAULT_MAX_TIME = 4.h

    SINGLE_MAX_CPU = 1
    SINGLE_MAX_MEM = 6.GB
    SINGLE_MAX_TIME = 4.h

    LOW_MAX_CPU = 4
    LOW_MAX_MEM = 12.GB
    LOW_MAX_TIME = 4.h

    MEDIUM_MAX_CPU = 12
    MEDIUM_MAX_MEM = 60.GB
    MEDIUM_MAX_TIME = 8.h

    HIGH_MAX_CPU = 25
    HIGH_MAX_MEM = 120.GB
    HIGH_MAX_TIME = 16.h

    LONG_MAX_TIME = 20.h
    HIGHMEM_MAX_MEM = 200.GB
    //

    // Default process resource requirements
    cpus = { check_max( DEFAULT_MAX_CPU * task.attempt, 'cpus' ) }
    memory = { check_max( DEFAULT_MAX_MEM * task.attempt, 'memory' ) }
    time = { check_max( DEFAULT_MAX_TIME * task.attempt, 'time' ) }

    errorStrategy = { task.exitStatus in ((130..145) + [104, 134, 137, 139, 140, 143]) ? 'retry' : 'finish' }
    maxRetries = 3
    maxErrors = '-1'

    // Process-specific resource requirements
    withLabel: process_single {
        cpus = { check_max( SINGLE_MAX_CPU, 'cpus' ) }
        memory = { check_max( SINGLE_MAX_MEM * task.attempt, 'memory' ) }
        time = { check_max( SINGLE_MAX_TIME * task.attempt, 'time' ) }
    }
    withLabel: process_low {
        cpus = { check_max( LOW_MAX_CPU * task.attempt, 'cpus' ) }
        memory = { check_max( LOW_MAX_MEM * task.attempt, 'memory' ) }
        time = { check_max( LOW_MAX_TIME * task.attempt, 'time' ) }
    }
    withLabel: process_medium {
        cpus = { check_max( MEDIUM_MAX_CPU * task.attempt, 'cpus' ) }
        memory = { check_max( MEDIUM_MAX_MEM * task.attempt, 'memory' ) }
        time = { check_max( MEDIUM_MAX_TIME * task.attempt, 'time' ) }
    }
    withLabel: process_high {
        cpus = { check_max( HIGH_MAX_CPU * task.attempt, 'cpus' ) }
        memory = { check_max( HIGH_MAX_MEM * task.attempt, 'memory' ) }
        time = { check_max( HIGH_MAX_TIME * task.attempt, 'time' ) }
    }
    withLabel: process_long {
        time = { check_max( LONG_MAX_TIME * task.attempt, 'time' ) }
    }
    withLabel: process_high_memory {
        memory = { check_max( HIGHMEM_MAX_MEM * task.attempt, 'memory' ) }
    }
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}

// Executor
executor {
    name = 'local'
    queueSize = 8
}

// Trace settings
trace {
    enabled = false
    file = "${params.outdir}/pipeline_reports/pipeline_trace.txt"
    fields = 'task_id,name,status,exit,realtime,%cpu,peak_rss,peak_vmem,container'
}